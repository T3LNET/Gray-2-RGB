{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T3LNET/DeepLearning/blob/main/Copy_of_gray_to_rgb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFmnDOnWpRm-"
      },
      "source": [
        "## Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fw2QGpQgc1Mr"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIZ3L_wmi_yQ"
      },
      "outputs": [],
      "source": [
        "!cp kaggle.json /root/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZWOm5d-DvWE"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d benjaminbirchhansen/img-net-10percent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dgl09pWPFEJ-"
      },
      "outputs": [],
      "source": [
        "!unzip img-net-10percent.zip -d img-net-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-djRQaTnoHsW"
      },
      "source": [
        "## imports  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QF4obycioGOt"
      },
      "outputs": [],
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import  os\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL conv"
      ],
      "metadata": {
        "id": "jUdf_jAuntsI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A43rQEPK5gfc"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Input(shape=(700, 525, 1)))\n",
        "\n",
        "model.add(layers.Conv2D(32, (4, 4), padding='same'))\n",
        "model.add(layers.MaxPool2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (4, 4), padding='same'))\n",
        "model.add(layers.MaxPool2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (4, 4), padding='same'))\n",
        "model.add(layers.MaxPool2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(256, ((4, 4))))\n",
        "model.add(layers.MaxPool2D((2, 2)))\n",
        "\n",
        "#-----------\n",
        "\n",
        "model.add(layers.Conv2D(128, (4, 4), padding = 'same'))\n",
        "model.add(layers.UpSampling2D(2))\n",
        "\n",
        "model.add(layers.Conv2D(64, (4, 4), padding= 'same'))\n",
        "model.add(layers.UpSampling2D(2))\n",
        "\n",
        "model.add(layers.Conv2D(32, (4, 4), padding= 'same'))\n",
        "model.add(layers.UpSampling2D(2))\n",
        "\n",
        "model.add(layers.Conv2D(10, (4, 4), padding= 'same'))\n",
        "model.add(layers.UpSampling2D(2))\n",
        "\n",
        "model.add(layers.Conv2D(3, (4, 4), padding= 'same'))\n",
        "model.add(layers.Activation('sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OHSM62p9144"
      },
      "outputs": [],
      "source": [
        "# model.output_shape()\n",
        "model.compile('sgd', 'mean_squared_error')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model VGG-16"
      ],
      "metadata": {
        "id": "xijPeQrfri8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "def build_model(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Custom VGG-16-like encoder for grayscale input\n",
        "    encoder = tf.keras.Sequential([\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    ])\n",
        "\n",
        "    encoder_output = encoder(inputs)\n",
        "\n",
        "    # Decoder\n",
        "    decoder = Conv2D(256, (3, 3), activation='relu', padding='same')(encoder_output)\n",
        "    decoder = UpSampling2D((2, 2))(decoder)\n",
        "    decoder = Conv2D(128, (3, 3), activation='relu', padding='same')(decoder)\n",
        "    decoder = UpSampling2D((2, 2))(decoder)\n",
        "    decoder = Conv2D(64, (3, 3), activation='relu', padding='same')(decoder)\n",
        "    decoder = UpSampling2D((2, 2))(decoder)\n",
        "    decoder = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(decoder)\n",
        "\n",
        "    model = tf.keras.Model(inputs, decoder)\n",
        "    return model\n",
        "\n",
        "input_shape = (224, 224, 1)  # Grayscale image input\n",
        "model = build_model(input_shape)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "bmVBAbE9rmli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary><b>TFRecord</b></summary>\n",
        "<code>\n",
        "# DataPath\n",
        "data_path = 'PATH'\n",
        "with tf.Session() as sess:\n",
        "    feature = {\n",
        "        'train/originals': tf.FixedLenFeature([], tf.string),\n",
        "\n",
        "        'train/labels': tf.FixedLenFeature([], tf.string)\n",
        "         }\n",
        "\n",
        "    filename_queue = tf.train.string_input_producer([data_path],num_epochs=None,shuffle=True,seed=1000000)\n",
        "\n",
        "    reader = tf.TFRecordReader()\n",
        "\n",
        "    _, serialized_example = reader.read(filename_queue)\n",
        "\n",
        "    features = tf.parse_single_example(serialized_example, features=feature)\n",
        "\n",
        "    originals = tf.decode_raw(features['train/originals'], tf.uint8)\n",
        "    labels = tf.decode_raw(features['train/labels'], tf.float64)\n",
        "\n",
        "    originals = tf.reshape(originals, [224, 224, 3])\n",
        "    originals = tf.cast(originals,tf.float32)\n",
        "    labels = tf.cast(labels, tf.float32)\n",
        "\n",
        "\n",
        "    labels = tf.reshape(labels,[1])\n",
        "    # init = tf.global_variables_initializer()\n",
        "    # sess.run(init)\n",
        "    # tf.train.start_queue_runners()\n",
        "\n",
        "    original , label = tf.train.shuffle_batch([originals, labels],  batch_size=10, capacity=30, num_threads=1, min_after_dequeue=10)\n",
        "\n",
        "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
        "    sess.run(init_op)\n",
        "\n",
        "\n",
        "    coord = tf.train.Coordinator()\n",
        "    threads = tf.train.start_queue_runners(coord=coord)\n",
        "\n",
        "    counter = 0\n",
        "    for batch_index in range(500000):\n",
        "        counter +=1\n",
        "        print(counter)\n",
        "        o,lab = sess.run([original,label])\n",
        "        print(o.shape)\n",
        "        print(lab[1])\n",
        "\n",
        "        # cv2.imshow('salam', np.array(o[1], dtype='uint8'))\n",
        "        # # cv2.waitKey(100)\n",
        "\n",
        "    coord.request_stop()\n",
        "\n",
        "    # Wait for threads to stop\n",
        "    coord.join(threads)\n",
        "    sess.close()\n",
        "</code>\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<code>\n",
        "data_path = 'PATH'\n",
        "\n",
        "def intt64Feature(value):\n",
        "    return  tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def bytesFeature(value):\n",
        "    return  tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def createDataSetTFRecord(data_path'''mnist_path''',tf_path):\n",
        "    data_splits = [\"train\",\"test\",\"validation\"]\n",
        "    # datasets = mnist.read_data_sets(mnist_path,dtype=tf.uint8,reshape=False,validation_size=1032)\n",
        "\n",
        "for d in range(len(data_splits)):\n",
        "        cur_split = data_splits[d]\n",
        "        print(\"saving \"+cur_split)\n",
        "        dataset = datasets[d]\n",
        "        file_name = os.path.join(tf_path,cur_split+\".tfrecord\")\n",
        "        print(file_name)\n",
        "        writer = tf.python_io.TFRecordWriter(file_name)\n",
        "\n",
        "        images_count = dataset.images.shape[0]\n",
        "        for index in range(images_count) :\n",
        "            cur_img =dataset.images[index]\n",
        "            image = cur_img.tostring()\n",
        "            example = tf.train.Example(features=tf.train.Features(\n",
        "                feature={\n",
        "                    'height':intt64Feature(dataset.images.shape[1]),\n",
        "                    'width':intt64Feature(dataset.images.shape[2]),\n",
        "                    'depth':intt64Feature(dataset.images.shape[3]),\n",
        "                    'label':intt64Feature(dataset.labels[index]),\n",
        "                    \"raw_image\":bytesFeature(image)\n",
        "                }\n",
        "            ))\n",
        "            writer.write(example.SerializeToString())\n",
        "        writer.close()\n",
        "\n",
        "#Load dataset\n",
        "def loadDataSetFromTFRecord(file_name):\n",
        "\n",
        "    data_iterator = tf.python_io.tf_record_iterator(file_name)\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            example_serialized = next(data_iterator)\n",
        "            example = tf.train.Example()\n",
        "            example.ParseFromString(example_serialized)\n",
        "\n",
        "            width = example.features.feature['width'].int64_list.value[0]\n",
        "            height = example.features.feature['height'].int64_list.value[0]\n",
        "            depth = example.features.feature['depth'].int64_list.value[0]\n",
        "            label = example.features.feature['label'].int64_list.value[0]\n",
        "            image = example.features.feature['raw_image'].bytes_list.value\n",
        "\n",
        "            flat_image = np.fromstring(image[0],np.uint8)\n",
        "            reshaped_img = flat_image.reshape((height,width,-1))\n",
        "            cv2.imshow(\"view\",reshaped_img)\n",
        "            cv2.waitKey(0)\n",
        "        except tf.errors.OutOfRangeError:\n",
        "            break\n",
        "</code>\n",
        "</details>"
      ],
      "metadata": {
        "id": "b0TuxNldn_rn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TFRECORD"
      ],
      "metadata": {
        "id": "_84M3rY_pJzL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0E4YnxekPZF"
      },
      "outputs": [],
      "source": [
        "# One class dataset\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Define the path to your single-class dataset and output TFRecord file\n",
        "dataset_path = 'PATH'\n",
        "tfrecord_filename = 'single_class_dataset.tfrecord'\n",
        "\n",
        "# Function to encode image as a feature\n",
        "def _bytes_feature(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "# Function to encode integer label as a feature\n",
        "def _int64_feature(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "# Open a TFRecord writer\n",
        "writer = tf.io.TFRecordWriter(tfrecord_filename)\n",
        "\n",
        "# Loop through each image in the single-class dataset\n",
        "for image_filename in os.listdir(dataset_path):\n",
        "    image_path = os.path.join(dataset_path, image_filename)\n",
        "    image = np.array(Image.open(image_path))  # Load and preprocess image\n",
        "    image_raw = image.tostring()  # Convert image to raw bytes\n",
        "\n",
        "    # Assuming the class label is 0 for a single class dataset\n",
        "    label = 0\n",
        "\n",
        "    # Create a feature\n",
        "    feature = {\n",
        "        'image_raw': _bytes_feature(image_raw),\n",
        "        'label': _int64_feature(label)\n",
        "    }\n",
        "\n",
        "    # Create an example protocol buffer\n",
        "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "    # Serialize the example to a string and write to the TFRecord file\n",
        "    writer.write(example.SerializeToString())\n",
        "\n",
        "# Close the TFRecord writer\n",
        "writer.close()\n",
        "\n",
        "# Parse TFRecord dataset for training\n",
        "def parse_function(example_proto):\n",
        "    features = {\n",
        "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64)\n",
        "    }\n",
        "    parsed_features = tf.io.parse_single_example(example_proto, features)\n",
        "\n",
        "    image = tf.image.decode_image(parsed_features['image_raw'])\n",
        "    image = preprocess_image(image)  # Define your preprocessing function\n",
        "\n",
        "    label = parsed_features['label']\n",
        "\n",
        "    return image, label\n",
        "\n",
        "# Create a TFRecordDataset\n",
        "dataset = tf.data.TFRecordDataset([tfrecord_filename])\n",
        "dataset = dataset.map(parse_function)\n",
        "dataset = dataset.shuffle(buffer_size=500)\n",
        "dataset = dataset.batch(batch_size=32)\n",
        "dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}